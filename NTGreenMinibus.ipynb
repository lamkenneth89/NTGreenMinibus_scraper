{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def scrape_minibus_routes(urls):\n",
        "    route_list = []\n",
        "    for url in urls:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        for link in soup.find_all('a', class_='category-page__member-link'):\n",
        "            route_code = link.get_text(strip=True)\n",
        "            route_url = 'https://hkbus.fandom.com' + link['href']\n",
        "            route_list.append([route_code, route_url])\n",
        "    df_routes = pd.DataFrame(route_list, columns=['Route Code', 'URL'])\n",
        "    return df_routes\n",
        "\n",
        "def scrape_vehicle_info(route_code, route_url):\n",
        "    response = requests.get(route_url)\n",
        "    response.raise_for_status()\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    target_section = soup.find('span', id='用車')\n",
        "    if target_section:\n",
        "        vehicle_table = target_section.find_next('table', class_='wikitable')\n",
        "        if vehicle_table:\n",
        "            rows = vehicle_table.find_all('tr')\n",
        "            vehicle_data = []\n",
        "            previous_seats = \"\"\n",
        "            for row in rows[1:]:\n",
        "                columns = row.find_all('td')\n",
        "                if len(columns) >= 3:\n",
        "                    vehicle_number = columns[0].get_text(strip=True)\n",
        "                    seats = columns[2].get_text(strip=True) if len(columns) >= 3 and columns[2].get_text(strip=True) else previous_seats\n",
        "                    vehicle_data.append([route_code, vehicle_number, seats])\n",
        "                    previous_seats = seats\n",
        "                elif len(columns) >= 2:\n",
        "                    vehicle_number = columns[0].get_text(strip=True)\n",
        "                    seats = previous_seats\n",
        "                    vehicle_data.append([route_code, vehicle_number, seats])\n",
        "            df_vehicle = pd.DataFrame(vehicle_data, columns=['Route Code', 'Vehicle Number', 'Seats'])\n",
        "            return df_vehicle\n",
        "    return pd.DataFrame(columns=['Route Code', 'Vehicle Number', 'Seats']) # Return empty DataFrame if no data found\n",
        "\n",
        "def process_route_details(df_routes):wW\n",
        "    all_vehicle_data = []\n",
        "    for _, row in df_routes.iterrows():\n",
        "        route_code, route_url = row['Route Code'], row['URL']\n",
        "        df_vehicle = scrape_vehicle_info(route_code, route_url)\n",
        "        if not df_vehicle.empty:\n",
        "            all_vehicle_data.append(df_vehicle)\n",
        "    df_all_vehicles = pd.concat(all_vehicle_data, ignore_index=True)\n",
        "    return df_all_vehicles\n",
        "\n",
        "def clean_and_extract_seats(df_vehicles):\n",
        "    previous_seats = \"\"\n",
        "    for index, row in df_vehicles.iterrows():\n",
        "        if \"座椅\" not in row[\"Seats\"]:\n",
        "            df_vehicles.loc[index, \"Seats\"] = previous_seats\n",
        "        previous_seats = row[\"Seats\"]\n",
        "    df_vehicles[\"Seats_edited\"] = df_vehicles[\"Seats\"].str.extract(r\"(\\d{2})\")\n",
        "\n",
        "    # Filter rows based on Vehicle Number format\n",
        "    pattern = r\"^[A-Z]{2}\\d{3,4}$\"  # Define the regex pattern\n",
        "    df_vehicles = df_vehicles[df_vehicles[\"Vehicle Number\"].str.match(pattern)]\n",
        "    return df_vehicles\n",
        "\n",
        "def generate_output(urls, output_file):\n",
        "    df_routes = scrape_minibus_routes(urls)\n",
        "    df_vehicles = process_route_details(df_routes)\n",
        "    df_cleaned = clean_and_extract_seats(df_vehicles)\n",
        "    df_final = pd.merge(df_cleaned, df_routes[['Route Code', 'URL']], on='Route Code', how='left')\n",
        "    df_final.to_csv(output_file, index=False, encoding='utf-8')\n",
        "    print(f\"Processed data saved to {output_file}\")\n",
        "    return df_final\n",
        "\n",
        "# Example Usage\n",
        "urls_to_scrape = [\n",
        "    \"https://hkbus.fandom.com/wiki/%E5%88%86%E9%A1%9E:%E6%96%B0%E7%95%8C%E5%B0%88%E7%B6%AB%E5%B0%8F%E5%B7%B4%E8%B7%AF%E7%B7%9A\",\n",
        "    \"https://hkbus.fandom.com/wiki/%E5%88%86%E9%A1%9E:%E6%96%B0%E7%95%8C%E5%B0%88%E7%B6%AB%E5%B0%8F%E5%B7%B4%E8%B7%AF%E7%B7%9A?from=087K%0A%E6%96%B0%E7%95%8C%E5%B0%88%E7%B6%AB%E5%B0%8F%E5%B7%B487K%E7%B7%9A\",\n",
        "    \"https://hkbus.fandom.com/wiki/%E5%88%86%E9%A1%9E:%E6%96%B0%E7%95%8C%E5%B0%88%E7%B6%AB%E5%B0%8F%E5%B7%B4%E8%B7%AF%E7%B7%9A?from=812%0A%E6%96%B0%E7%95%8C%E5%B0%88%E7%B6%AB%E5%B0%8F%E5%B7%B4812%E7%B7%9A\"\n",
        "]\n",
        "\n",
        "output_file = \"minibus_vehicle_info.csv\"\n",
        "\n",
        "df_final = generate_output(urls_to_scrape, output_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "on8OSxRjb3nJ",
        "outputId": "a1d03ad3-ff00-4bb8-d39f-0fcf75f19823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed data saved to minibus_vehicle_info.csv\n"
          ]
        }
      ]
    }
  ]
}